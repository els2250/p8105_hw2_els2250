---
title: "Homework 2"
author: Emma Sexton <br>
date: "Due: 5 October 2022"
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

The goal of this problem is to import data and use the `select`, `filter`, `mutate`, and `pivot_longer` commands to summarize the dataset and answer data-specific questions. 

```{r}
nyc_transit_df <- 
  read_csv(
    'data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv',
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%  
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entrance_type, entry, vending, ada) %>%  
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

#### Summary of Dataset:

Above, we imported the `NYC_Transit_Subway_Entrance_And_Exit_Data.csv` data which has 1868 rows (observations) and 20 columns (variables). We also converted `route` variables 8-11 to character types to be consistent with 1-7. Additionally, we retained the following variables: line, station name, station latitude / longitude, route served, entry, vending, entrance type, and ADA compliance. We also updated `entry` from being a character with `YES` and `NO` values to a logical vector. 

Although clean, the dataframe is not 'tidy'. Two new variables - `route_name` and `route_number` - need to be created to manipulate the `route` variables from wide to long format. This can be used to answer questions related to specific routes, but it may not be helpful for answering questions that focus on station-level variables as it'll repeat observations.

#### *Q1.1: How many distinct stations are there?*
To determine the number of distinct stations, we can select station name and line using the `distinct()` function. The number of rows in the dataset equals the number of unique stations. 

```{r}
unique_stations <- nyc_transit_df %>% 
  select(station_name, line) %>% 
  distinct
```

According to the chunk code above, there are **465 unique stations**. 

#### *Q1.2: How many stations are ADA compliant?*

To determine the number of stations that are ADA compliant, we can filter on the `ada` variable using `filter()`. 

```{r}
ada_compliant <- nyc_transit_df %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

According to the chunk code above, there are **84 stations that are ADA compliant**. 

#### *Q1.3: What proportion of station entrances / exits without vending allow entrance?*

```{r}
entrance_wo_vending <- nyc_transit_df %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Here, we filtered on `vending == NO` and extracted a single column (here, `entry`). Taking the mean of a logical variable allows us to determine the proportion of entrances to exits, and we discover that **37.7% of station entrances/exits without vending allow entrance**. 

#### *Q1.4: How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?*

Next, we will reformat the data so that `route_number` and `route_name` are distinct variables. In tidying the data using `pivot_longer`, we are able to reformat the data from wide to long, which allows us to answer route specific questions as noted earlier. 

```{r}
transit_A <- nyc_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% 
  filter(route_name == "A") %>% 
  select(station_name, line) %>% 
  distinct

transit_A_ada <- nyc_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

In this chunk, we are pivoting the data and creating `route_number` and `route_name`, then filtering to choose the A train and ADA compliant stations. We then use the chunk code that we've used in previous questions to pull the distinct station names. There are **60 distinct stations that serve the A train**. Of those 60 stations, there are **17 stations that serve the A train and are ADA compliant**. 


## Problem 2

The goal of this problem is to import, clean, and organize two datasets (`Mr. Trash Wheel` and `Professor Trash Wheel`), and then join the two datasets. 

We will start with importing, cleaning, and organizing `Mr. Trash Wheel`...

```{r}
mr_trash_wheel <- 
  read_excel("data/Trash_Wheel_Collection_Data.xlsx", 
                            sheet = "Mr. Trash Wheel", 
                            range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls),
         trash_program = "Mr. Trash Wheel",
         year = as.character(year)) %>% 
  filter(!is.na(dumpster))
```

Note: We used `as.integer` to round `sports_balls`, but we could also use the `round` function and code `digits = 0` to achieve the same outcome. 


Next, we will import, clean, and organize `Professor Trash Wheel`...

```{r}
prof_trash_wheel <- 
  read_excel("data/Trash_Wheel_Collection_Data.xlsx", 
                            sheet = "Professor Trash Wheel", 
                            range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  mutate(trash_program = "Professor Trash Wheel",
         year = as.character(year)) %>% 
  filter(!is.na(dumpster))
```

Now that both datasets are clean and organized, we will join them using `bind_rows()`...

```{r}
trash_wheel_tidy <-
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

#### Summary of Dataset:

The `Mr. Trash Wheel` dataset consisted of `r nrow(mr_trash_wheel)` observations of `r ncol(mr_trash_wheel)` variables, while the `Professor Trash Wheel` dataset consisted of `r nrow(prof_trash_wheel)` observations of `r ncol(prof_trash_wheel)` variables. Combining these two datasets, the `trash_wheel_tidy` dataset consists of `r nrow(trash_wheel_tidy)` observations of `r ncol(trash_wheel_tidy)` variables. Generally, the dataset details dumpster number, date of collection, amount of total litter, and litter type. Key variables include:

* `dumpster`: Integer variable depicting the dumpster number (range = 1-547 for Mr. Trash Wheel and 1-94 for Professor Trash Wheel)
* `date`: Datetime variable describing the dates garbage was collected (range = May 2014 to July 2022)
* `weight_tons`: Integer variable describing the weight of garbage collected in tons (total sum = `r sum(trash_wheel_tidy$weight_tons)` tons)
* `volume_cubic_yards`: Integer variable describing the volume of garbage collected in cubic yards (total sum = `r sum(trash_wheel_tidy$volume_cubic_yards)` cubic yards)
* Integer variables describing the different types of litter collected, such as:
    * `plastic_bottles`: Plastic bottles (total sum = `r sum(trash_wheel_tidy$plastic_bottles)`)
    * `polystyrene`: Polystyrene (total sum = `r sum(trash_wheel_tidy$polystyrene)`)
    * `cigarette_butts`: Cigarette butts (total sum = `r sum(trash_wheel_tidy$cigarette_butts)`)
    * `glass_bottles`: Glass bottles (total sum = `r sum(trash_wheel_tidy$glass_bottles)`)
    * `grocery_bags`: Grocery bags (total sum = `r sum(trash_wheel_tidy$grocery_bags)`)
    * `chip_bags`: Chip bags (total sum = `r sum(trash_wheel_tidy$chip_bags)`)
    * `sports_balls`: Sports balls (total sum = `r sum(trash_wheel_tidy$sports_balls, na.rm = TRUE)`)
* `homes_powered`: Integer variable describing the number of homes powered from collected garbage (total = `r sum(trash_wheel_tidy$homes_powered, na.rm = TRUE)` homes)
* `trash_program`: Character variable describing which water-wheel vessel was removing the litter (`Mr. Trash Wheel` or `Professor Trash Wheel`)
    

#### *Q2.1: What was the total weight of trash collected by Professor Trash Wheel?*

```{r}
trash_wheel_tidy %>% 
  filter(trash_program == "Professor Trash Wheel") %>% 
  summarise(sum(weight_tons), na.rm = TRUE)
```

The total weight collected by `Professor Trash Wheel` was **around 190 tons**.

#### *Q2.2: What was the total number of sports balls collected by Mr. Trash Wheel in 2020?*

```{r}
trash_wheel_tidy %>% 
  filter(trash_program == "Mr. Trash Wheel", year == "2020") %>% 
  summarise(sum(sports_balls), na.rm = TRUE)
```

Mr. Trash Wheel collected **856 sports balls** in 2020. 


## Problem 3

The goal of this problem is to merge `pols-month.csv`, `unemployment.csv`, and `snp.csv` into a singe data frame using year and month as keys across datasets. 

To start, we need to import and clean pols-month.csv...

```{r}
national_pols <- read_csv('data/fivethirtyeight_datasets/pols-month.csv') %>% 
  janitor::clean_names() %>% 
  separate(col = mon, into = c('year', 'month', 'day'), sep = '-') %>% 
  mutate(month = recode(month,
                        '01' = 'January',
                        '02' = 'February',
                        '03' = 'March',
                        '04' = 'April',
                        '05' = 'May',
                        '06' = 'June',
                        '07' = 'July',
                        '08' = 'August',
                        '09' = 'September',
                        '10' = 'October',
                        '11' = 'November',
                        '12' = 'December'),
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>% 
  select(-c(prez_dem, prez_gop, day))
```

Next, we will import and clean snp.csv using a similar process as above...

```{r}
snp_stock_market <- read_csv('data/fivethirtyeight_datasets/snp.csv') %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, "%m/%d/%y"),
         date = if_else(date > "2015-07-01", format(date, "19%y-%m-%d"), format(date))) %>% 
  separate(col = date, into = c('year', 'month', 'day'), sep = '-') %>% 
  mutate(month = recode(month,
                        '01' = 'January',
                        '02' = 'February',
                        '03' = 'March',
                        '04' = 'April',
                        '05' = 'May',
                        '06' = 'June',
                        '07' = 'July',
                        '08' = 'August',
                        '09' = 'September',
                        '10' = 'October',
                        '11' = 'November',
                        '12' = 'December')) %>% 
  arrange(year, factor(month, levels = month.name)) %>% 
  select(-day)
```

Next, we will import and clean the unemployment.csv data...

```{r}
unemployment <- read_csv('data/fivethirtyeight_datasets/unemployment.csv') %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent"
  ) %>% 
  mutate(month = recode(month,
                        'jan' = 'January',
                        'feb' = 'February',
                        'mar' = 'March',
                        'apr' = 'April',
                        'may' = 'May',
                        'jun' = 'June',
                        'jul' = 'July',
                        'aug' = 'August',
                        'sep' = 'September',
                        'oct' = 'October',
                        'nov' = 'November',
                        'dec' = 'December'),
         year = as.character(year))
```


Finally, we will merge all three datasets matching month and year, starting with `national_politians` and `snp_stock_market`, then adding `unemployment` to the result of that merge. 

```{r}
tidy_pols_snp <- full_join(national_pols, snp_stock_market, by = c("year", "month"))
tidy_pols_snp_unemp <- full_join(tidy_pols_snp, unemployment, by = c("year", "month"))
```

NOTE: Here, I decided to use `full_join` since I know that the number of variables and the number of observations do not match in each data set. To avoid losing any data, I decided to merge all information based on `year` and `month`. 

#### Summary of Dataset(s):
The `national_pols` data set consists of **`r nrow(national_pols)` observations** of **`r ncol(national_pols)` variables**. This data set detailed the months (`month`) and years (`year`) corresponding to the number of Democrat and Republican governors (`gov_dem` and `gov_rep`, respectively), senators (`sen_dem` and `sen_gop`, respectively), and representatives (`rep_dem` and `rep_gop`, respectively). A variable describing the political party of the president (`president`) was also included. Considering the `year` variable, the data set ranged from **`r min(national_pols$year)` to `r max(national_pols$year)`**. 

The `snp_stock_market` data set consists of **`r nrow(snp_stock_market)` observations** of **`r ncol(snp_stock_market)` variables**. This data set detailed the months (`month`) and years (`year`) corresponding to the closing values (`close`) of Standard & Poor's (S&P) stock market index. The years range from **`r min(snp_stock_market$year)` to `r max(snp_stock_market$year)`**, and the closing values ranged from **`r min(snp_stock_market$close)` to `r max(snp_stock_market$close)`**. It's important to note that the `snp_stock_market` data set provides projections into future years. 

The `unemployment` data set consists of **`r nrow(unemployment)` observations** of **`r ncol(unemployment)` variables**. This data set detailed the months (`month`) and years (`year`) corresponding to unemployment rates expressed as percents (`percent`). The years ranged from **`r min(unemployment$year)` to `r max(unemployment$year)`**, and the unemployment rates ranged from **`r min(unemployment$percent, na.rm = TRUE)`% to `r max(unemployment$percent, na.rm = TRUE)`%**. 

The final data set, `tidy_pols_snp_unemp`, merged these three data frames based on `year` and `month`. The `tidy_pols_snp_unemp` data set contains **`r nrow(tidy_pols_snp_unemp)` observations** of **`r ncol(tidy_pols_snp_unemp)` variables**. The data set compiled all previously mentioned variables from the past three data sets and matched them to month and year. Considering the `year` variable, the final data set ranges from **`r min(tidy_pols_snp_unemp$year)` to `r max(tidy_pols_snp_unemp$year)`**. Since I joined the three data sets using `full_join`, R automatically filled missing data with `NA`. With this data set, we are able to compare the number of Democrat vs. Republic governors, senators, and representatives, the political party of the president, the stock closing value, and unemployment rates in each month-year pair. 

