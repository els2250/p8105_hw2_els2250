Homework 2
================
Emma Sexton <br>
Due: 5 October 2022

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

The goal of this problem is to import data and use the `select`,
`filter`, `mutate`, and `pivot_longer` commands to summarize the dataset
and answer data-specific questions.

``` r
nyc_transit_df <- 
  read_csv(
    'data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv',
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%  
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entrance_type, entry, vending, ada) %>%  
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

#### Summary of Dataset:

Above, we imported the `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`
data which has 1868 rows (observations) and 20 columns (variables). We
also converted `route` variables 8-11 to character types to be
consistent with 1-7. Additionally, we retained the following variables:
line, station name, station latitude / longitude, route served, entry,
vending, entrance type, and ADA compliance. We also updated `entry` from
being a character with `YES` and `NO` values to a logical vector.

Although clean, the dataframe is not ‘tidy’. Two new variables -
`route_name` and `route_number` - need to be created to manipulate the
`route` variables from wide to long format. This can be used to answer
questions related to specific routes, but it may not be helpful for
answering questions that focus on station-level variables as it’ll
repeat observations.

#### *Q1.1: How many distinct stations are there?*

To determine the number of distinct stations, we can select station name
and line using the `distinct()` function. The number of rows in the
dataset equals the number of unique stations.

``` r
unique_stations <- nyc_transit_df %>% 
  select(station_name, line) %>% 
  distinct
```

According to the chunk code above, there are **465 unique stations**.

#### *Q1.2: How many stations are ADA compliant?*

To determine the number of stations that are ADA compliant, we can
filter on the `ada` variable using `filter()`.

``` r
ada_compliant <- nyc_transit_df %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

According to the chunk code above, there are **84 stations that are ADA
compliant**.

#### *Q1.3: What proportion of station entrances / exits without vending allow entrance?*

``` r
entrance_wo_vending <- nyc_transit_df %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Here, we filtered on `vending == NO` and extracted a single column
(here, `entry`). Taking the mean of a logical variable allows us to
determine the proportion of entrances to exits, and we discover that
**37.7% of station entrances/exits without vending allow entrance**.

#### *Q1.4: How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?*

Next, we will reformat the data so that `route_number` and `route_name`
are distinct variables. In tidying the data using `pivot_longer`, we are
able to reformat the data from wide to long, which allows us to answer
route specific questions as noted earlier.

``` r
transit_A_ada <- nyc_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name") %>% 
  filter(route_name == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

In this chunk, we are pivoting the data and creating `route_number` and
`route_name`, then filtering to choose the A train and ADA compliant
stations. We then use the chunk code that we’ve used in previous
questions to pull the distinct station names. There are **17 stations
that serve the A train and are ADA compliant**.

## Problem 2

The goal of this problem is to import, clean, and organize two datasets
(`Mr. Trash Wheel` and `Professor Trash Wheel`), and then join the two
datasets.

We will start with importing, cleaning, and organizing
`Mr. Trash Wheel`…

``` r
mr_trash_wheel <- 
  read_excel("data/Trash_Wheel_Collection_Data.xlsx", 
                            sheet = "Mr. Trash Wheel", 
                            range = "A2:N549") %>% 
  janitor::clean_names() %>% 
  mutate(sports_balls = as.integer(sports_balls),
         trash_program = "Mr. Trash Wheel",
         year = as.character(year)) %>% 
  filter(!is.na(dumpster))
```

Note: We used `as.integer` to round `sports_balls`, but we could also
use the `round` function and code `digits = 0` to achieve the same
outcome.

Next, we will import, clean, and organize `Professor Trash Wheel`…

``` r
prof_trash_wheel <- 
  read_excel("data/Trash_Wheel_Collection_Data.xlsx", 
                            sheet = "Professor Trash Wheel", 
                            range = "A2:M96") %>% 
  janitor::clean_names() %>% 
  mutate(trash_program = "Professor Trash Wheel",
         year = as.character(year)) %>% 
  filter(!is.na(dumpster))
```

Now that both datasets are clean and organized, we will join them using
`rbind()`…

``` r
trash_wheel_tidy <-
  bind_rows(mr_trash_wheel, prof_trash_wheel)
```

#### Summary of Dataset:

The `Mr. Trash Wheel` dataset consisted of 547 observations of 15
variables, while the `Professor Trash Wheel` dataset consisted of 94
observations of 14 variables. Combining these two datasets, the
`trash_wheel_tidy` dataset consists of 641 observations of 15 variables.
Generally, the dataset details dumpster number, date of collection,
amount of total litter, and litter type. Key variables include:

-   `dumpster`: Integer variable depicting the dumpster number (range =
    1-547 for Mr. Trash Wheel and 1-94 for Professor Trash Wheel)
-   `date`: Datetime variable describing the dates garbage was collected
    (range = May 2014 to July 2022)
-   `weight_tons`: Integer variable describing the weight of garbage
    collected in tons (total sum = 1938.48 tons)
-   `volume_cubic_yards`: Integer variable describing the volume of
    garbage collected in cubic yards (total sum = 9756 cubic yards)
-   Integer variables describing the different types of litter
    collected, such as:
    -   `plastic_bottles`: Plastic bottles (total sum = 1.579941^{6})
    -   `polystyrene`: Polystyrene (total sum = 1.33893^{6})
    -   `cigarette_butts`: Cigarette butts (total sum = 1.2604498^{7})
    -   `glass_bottles`: Glass bottles (total sum = 1.3273^{4})
    -   `grocery_bags`: Grocery bags (total sum = 7.8052^{5})
    -   `chip_bags`: Chip bags (total sum = 1.541951^{6})
    -   `sports_balls`: Sports balls (total sum = 6869)
-   `homes_powered`: Integer variable describing the number of homes
    powered from collected garbage (total = 2.5053^{4} homes)
-   `trash_program`: Character variable describing which water-wheel
    vessel was removing the litter (`Mr. Trash Wheel` or
    `Professor Trash Wheel`)

#### *Q2.1: What was the total weight of trash collected by Professor Trash Wheel?*

``` r
trash_wheel_tidy %>% 
  filter(trash_program == "Professor Trash Wheel") %>% 
  summarise(sum(weight_tons), na.rm = TRUE)
## # A tibble: 1 × 2
##   `sum(weight_tons)` na.rm
##                <dbl> <lgl>
## 1               190. TRUE
```

The total weight collected by `Professor Trash Wheel` was **around 190
tons**.

#### *Q2.2: What was the total number of sports balls collected by Mr. Trash Wheel in 2020?*

``` r
trash_wheel_tidy %>% 
  filter(trash_program == "Mr. Trash Wheel", year == "2020") %>% 
  summarise(sum(sports_balls), na.rm = TRUE)
## # A tibble: 1 × 2
##   `sum(sports_balls)` na.rm
##                 <int> <lgl>
## 1                 856 TRUE
```

Mr. Trash Wheel collected **856 sports balls** in 2020.

## Problem 3

The goal of this problem is to merge `pols-month.csv`,
`unemployment.csv`, and `snp.csv` into a singe data frame using year and
month as keys across datasets.

To start, we need to import and clean pols-month.csv…

``` r
national_politians <- read_csv('data/fivethirtyeight_datasets/pols-month.csv') %>% 
  janitor::clean_names() %>% 
  separate(col = mon, into = c('year', 'month', 'day'), sep = '-') %>% 
  mutate(month = recode(month,
                        '01' = 'January',
                        '02' = 'February',
                        '03' = 'March',
                        '04' = 'April',
                        '05' = 'May',
                        '06' = 'June',
                        '07' = 'July',
                        '08' = 'August',
                        '09' = 'September',
                        '10' = 'October',
                        '11' = 'November',
                        '12' = 'December'),
         president = ifelse(prez_gop == 1, "gop", ifelse(prez_dem == 1, "dem", NA))) %>% 
  select(-c(prez_dem, prez_gop, day))
```

Next, we will import and clean snp.csv using a similar process as above…

``` r
snp_stock_market <- read_csv('data/fivethirtyeight_datasets/snp.csv') %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, "%m/%d/%y")) %>% 
  separate(col = date, into = c('year', 'month', 'day'), sep = '-') %>% 
  mutate(month = recode(month,
                        '01' = 'January',
                        '02' = 'February',
                        '03' = 'March',
                        '04' = 'April',
                        '05' = 'May',
                        '06' = 'June',
                        '07' = 'July',
                        '08' = 'August',
                        '09' = 'September',
                        '10' = 'October',
                        '11' = 'November',
                        '12' = 'December')) %>% 
  arrange(year, factor(month, levels = month.name)) %>% 
  select(-day)
```

Next, we will import and clean the unemployment.csv data…

``` r
unemployment <- read_csv('data/fivethirtyeight_datasets/unemployment.csv') %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percent"
  ) %>% 
  mutate(month = recode(month,
                        'jan' = 'January',
                        'feb' = 'February',
                        'mar' = 'March',
                        'apr' = 'April',
                        'may' = 'May',
                        'jun' = 'June',
                        'jul' = 'July',
                        'aug' = 'August',
                        'sep' = 'September',
                        'oct' = 'October',
                        'nov' = 'November',
                        'dec' = 'December'),
         year = as.character(year))
```

Finally, we will merge all three datasets matching month and year,
starting with `national_politians` and `snp_stock_market`, then adding
`unemployment` to the result of that merge.

#### Summary of Dataset(s)
